{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQ-2Cd05GfEu"
   },
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"https://www.uoc.edu/content/dam/news/images/noticies/2016/202-nova-marca-uoc.jpg\" align=\"left\" width=\"45%\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.891 · Aprendizaje automático · PEC4</p>\n",
    "<p style=\"margin: 0; text-align:right;\">2024-1 · Máster universitario en Ciencia de datos (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8W7tt0JcI9Dx"
   },
   "source": [
    "# **PEC 4: Aprendizaje con Ensemble Avanzado, Transfer Learning y Evaluación de Modelos**\n",
    "\n",
    "## **Objetivo:**\n",
    "El objetivo principal de esta cuarta PEC es consolidar los conocimientos adquiridos en las PECs anteriores e introducir técnicas avanzadas de ensemble y transfer learning. Esta práctica le ayudará a entender cómo combinar varios modelos y aplicar aprendizaje profundo preentrenado para mejorar el rendimiento, evaluándolos críticamente con métricas adecuadas. Nos centraremos en métricas como la sensibilidad y la especificidad, especialmente importantes en el contexto médico.\n",
    "\n",
    "## **Contexto:**\n",
    "Después de completar las PECs anteriores (PAC 1, PAC 2 y PAC 3), ya está familiarizado con la preparación de datos, el aprendizaje supervisado y no supervisado, la reducción de dimensionalidad y el manejo de conjuntos de datos desbalanceados. En esta PAC 4, aplicará estas habilidades utilizando técnicas avanzadas como Bagging, Boosting, Stacking, Cascading y Transfer Learning con un modelo preentrenado adaptado para datos tabulares.\n",
    "\n",
    "### **Conjunto de Datos:**\n",
    "Trabajará con un conjunto de datos real sobre diabetes. Estos datos contienen varias variables clínicas que permiten predecir si un paciente tiene diabetes. Su primer paso será preparar los datos y realizar un análisis exploratorio. A continuación, comparará dos enfoques:\n",
    "\n",
    "1. Utilizar las variables originales como descriptores.\n",
    "2. Utilizar los principales componentes (PCs) obtenidos del Análisis de Componentes Principales (PCA) como descriptores.\n",
    "\n",
    "Además, aplicará **Transfer Learning** utilizando un modelo de red neuronal preentrenado para mejorar el rendimiento de su mejor modelo.\n",
    "\n",
    "---\n",
    "\n",
    "## **Resumen de las Tareas:**\n",
    "\n",
    "### **1. Preparación de Datos y Análisis Exploratorio (EDA) (0.5 puntos)**\n",
    "\n",
    "- Cargue el conjunto de datos sobre diabetes.\n",
    "- Realice un análisis estadístico básico.\n",
    "- Realice un análisis exploratorio de datos (EDA) con visualizaciones para entender la distribución y correlación.\n",
    "- Limpie y preprocesamente los datos, incluyendo el tratamiento de valores perdidos y valores atípicos.\n",
    "\n",
    "### **2. Reducción de Dimensionalidad (1 punto)**\n",
    "\n",
    "- Preparación: Se separan a los pacientes diabéticos para el entrenamiento del PCA. Divide los datos diabéticos en entrenamiento/validación (80%) y pruebas (20%), random state=42.\n",
    "- Normalización y construcción del modelo PCA: Se normalizan los datos y se crea el modelo de los componentes principales con el conjunto de pacientes de entrenamiento del paso anterior (diabéticos)\n",
    "- Proyección de los Datos Restantes: Utilizamos el modelo creado en el paso anterior para proyectar tanto los datos de test de los pacientes diabéticos como los datos de los pacientes no diabéticos.\n",
    "- Creación del Conjunto de Entrenamiento para Clasificación: El conjunto de datos proyectado se utiliza como entrada para los modelos de clasificación.\n",
    "\n",
    "### **3. Entrenamiento y Evaluación de Modelos Base (2.5 puntos)**\n",
    "\n",
    "- Entrene modelos base con las variables originales como descriptores.\n",
    "- Entrene modelos base con los componentes principales (PCs) como descriptores.\n",
    "- Evalúe los modelos utilizando métricas de exactitud, sensibilidad, especificidad, ROC-AUC y análisis de la matriz de confusión.\n",
    "\n",
    "### **4. Técnicas Avanzadas de Ensemble (3 puntos)**\n",
    "\n",
    "- Implemente y evalúe técnicas de ensemble como Bagging, Boosting, Stacking y Cascading utilizando las variables originales.\n",
    "- Repita la implementación con los componentes principales como descriptores.\n",
    "- Compare el rendimiento de cada método y analice los resultados.\n",
    "\n",
    "### **5. Convolutional Neural Network para Datos Tabulares (1 punto + 1 punto adicional)**\n",
    "\n",
    "- Diseña un modelo Convolutional Neural Network (CNN) para datos tabulares.\n",
    "- Entrene el modelo utilizando los datos preprocesados y compare el rendimiento con los métodos de ensemble.\n",
    "- Evalúe el modelo utilizando exactitud, sensibilidad, especificidad, ROC-AUC y matriz de confusión.\n",
    "- Adapte, entrene y evalúe un modelo de red neuronal preentrenado (ResNet50) para datos tabulares (opcional, 1 punto extra).\n",
    "\n",
    "\n",
    "### **6. Optimización del Modelo y Sintonización de Hiperparámetros (2 puntos)**\n",
    "\n",
    "- Realice una sintonización de hiperparámetros con GridSearchCV para el mejor modelo de ensemble.\n",
    "- Evalúe el modelo optimizado en el conjunto de test.\n",
    "\n",
    "---\n",
    "\n",
    "### **Importante:**\n",
    "- La entrega debe ser en formato Jupyter Notebook (*.ipynb) y HTML.\n",
    "- No utilice métodos o funciones declarados \"deprecated\".\n",
    "- Incluya su nombre y apellidos en la solución.\n",
    "- Utilice celdas Markdown para responder a las preguntas teóricas.\n",
    "\n",
    "---\n",
    "\n",
    "Esta PAC está diseñada para desafiar su comprensión sobre técnicas de ensemble avanzadas y transfer learning, ofreciendo una visión completa de cómo mejorar el rendimiento de los modelos en contextos médicos. Al final de esta PAC, será capaz de:\n",
    "\n",
    "- Aplicar técnicas avanzadas para mejorar el rendimiento de los modelos de clasificación.\n",
    "- Utilizar transfer learning para aumentar la eficiencia de los modelos en datos tabulares.\n",
    "- Evaluar los modelos utilizando métricas relevantes en el contexto médico, con énfasis en sensibilidad y especificidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDpnuGAqKhr9"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Nombre y apellidos: Víctor M. Sola Rodríguez</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_mbfr5YLK55"
   },
   "source": [
    "Para la realización de la práctica, necesitaremos importar los siguientes módulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 27762,
     "status": "ok",
     "timestamp": 1734535402331,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "qisjzTtaLPhj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: keras_tuner in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (1.4.7)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.69.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from keras_tuner) (1.0.5)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from imbalanced-learn) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn)\n",
      "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Requirement already satisfied: rich in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vik\\anaconda3\\envs\\pec4\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sklearn-compat, imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.13.0 sklearn-compat-0.1.3\n"
     ]
    }
   ],
   "source": [
    "# Upgrade pip to ensure compatibility\n",
    "!pip install --upgrade pip --quiet \n",
    "# Keep active\n",
    "\n",
    "# Install required libraries with quiet output\n",
    "!pip install scikit-learn tensorflow keras-tuner --quiet  \n",
    "# Keep active\n",
    "!pip install numpy pandas seaborn matplotlib tensorflow keras_tuner imbalanced-learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier # Import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, accuracy_score, confusion_matrix, roc_auc_score, RocCurveDisplay, classification_report\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten, BatchNormalization, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Ensure that plots are displayed inline (especially useful for Jupyter Notebooks and Colab)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1lgHpHHZmx5"
   },
   "source": [
    "### ¿Por qué utilizar Google Colab para esta PEC 4?\n",
    "\n",
    "Teniendo en cuenta los requisitos de esta PEC 4, que incluyen **cálculos intensivos**, **modelos preentrenados** y la necesidad de **resultados consistentes y reproducibles**, Google Colab ofrece una plataforma robusta, eficiente y accesible. Entre sus principales ventajas destacan:\n",
    "\n",
    "1. **Acceso a Hardware Potente (GPU/TPU gratuitas):**  \n",
    "   Google Colab ofrece acceso gratuito a GPUs y TPUs, lo que resulta especialmente útil para entrenar modelos complejos, especialmente al implementar el **transfer learning**. El uso de una GPU puede reducir significativamente el tiempo de entrenamiento de los modelos, acelerando el proceso de experimentación.\n",
    "\n",
    "2. **Sin Necesidad de Configuración Local:**  \n",
    "   Se puede evitar la complejidad de configurar el entorno local con todas las dependencias necesarias. Colab viene preconfigurado con las versiones más recientes de bibliotecas esenciales de Python como **Scikit-Learn, TensorFlow, PyTorch**, y otras que se utilizan en esta PEC. Esto reduce los problemas de compatibilidad y asegura una ejecución fluida del notebook.\n",
    "\n",
    "3. **Integración Sencilla con Google Drive:**  \n",
    "   Colab permite una integración directa con Google Drive, facilitando la tarea de guardar los progresos, conjuntos de datos y modelos sin preocuparse por las limitaciones de almacenamiento local. Esta característica es especialmente útil cuando se trabaja con conjuntos de datos grandes, como el conjunto de datos de diabetes utilizado en esta PEC.\n",
    "\n",
    "4. **Acceso a Modelos Preentrenados:**  \n",
    "   Cuando se aplica **transfer learning**, a menudo es necesario descargar grandes modelos preentrenados (como ResNet, VGG). Colab tiene una conexión a internet rápida, lo que facilita el acceso y la carga de estos modelos de manera más rápida que en un entorno local típico.\n",
    "\n",
    "5. **Reproducibilidad y Consistencia:**  \n",
    "   Utilizar un entorno en la nube como Colab asegura una ejecución consistente para todos, ya que se emplea la misma configuración. Esto reduce la variabilidad en los resultados debido a diferencias en el hardware o en la configuración del software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XICnpHHi7BEh"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong> Abre Colab, permite que acceda a Google Drive y crea un directorio de trabajo:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1734535404008,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "FxayOYGU_7TF",
    "outputId": "312fc846-9781-47e3-d3e2-458e517f03df"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGStOSRTbHsO"
   },
   "source": [
    "### **1. Preparación de Datos y Análisis Exploratorio (EDA) (0.5 puntos)**\n",
    "\n",
    "- 1.1. Cargad el conjunto de datos sobre diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LF9_DgWdEMvh"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong> carga el archivo en un dataframe. Verifica los tipos de variables.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1734535404008,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "h65dhLntcZ-1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZCkLwKWcaoQ"
   },
   "source": [
    "- 1.2. Análisis estadístico básico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Db2qwMbCE_0f"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong> Realiza el análisis estadístico básico.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734535404008,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "GpruLhQIeYUd",
    "outputId": "6be916d6-3555-46c4-877b-88f560fb0c62"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95i_u_zTcpSQ"
   },
   "source": [
    "- 1.3. Realizad un análisis exploratorio de datos (EDA) con visualizaciones para entender la distribución y correlación.  \n",
    "1.3.1. Análisis de Variables Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1734535404008,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "csKvO5xRmhAn",
    "outputId": "0b3ec752-fe0f-436b-b29f-937b47ece9cc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVsXVSX3fWhd"
   },
   "source": [
    "1.3.2. Análisis de Variables Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3694
    },
    "executionInfo": {
     "elapsed": 7691,
     "status": "ok",
     "timestamp": 1734535411696,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "DsjDm96hfXJ4",
    "outputId": "b87c5d8a-4a22-4846-d1d1-03ec67e387f2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4olAj5skmrO"
   },
   "source": [
    "1.3.3. Matriz de Correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 866
    },
    "executionInfo": {
     "elapsed": 2030,
     "status": "ok",
     "timestamp": 1734535413725,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "hRVN5OMNkn-w",
    "outputId": "a50e0fcf-c474-45eb-9cfb-75dae6d85dc7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "El38tdHme68Z"
   },
   "source": [
    "- 1.4. Preprocesamiento de datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9qhrxnZFRV-"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong> Limpia y preprocesa los datos, incluyendo el tratamiento de valores perdidos y valores atípicos.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1734535413726,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "8CxV0Tr2kxDT",
    "outputId": "16466ae1-9fad-4de2-8b1c-888d46e69366"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29jw_2HHYMMM"
   },
   "source": [
    "- 1.5. Balanceo de clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSZH-_nkGO0G"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong> Verificación de la distribución de clases.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1734535414080,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "xdV2x6DrYY02",
    "outputId": "ff56467d-c02a-4ec5-b028-80a3fcb604fd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NdE-HifZT15"
   },
   "source": [
    "Dado que tenemos previsto utilizar redes neuronales y transferencia de aprendizaje o transfer learning (que puede gestionar bien grandes conjuntos de datos), el mejor método sería una combinación de **SMOTE** y **ADASYN**:\n",
    "\n",
    "- Primero utiliza **SMOTE**. Ayudará a crear un conjunto de datos equilibrado con muestras sintéticas (random_state=42).  \n",
    "- Después **ADASYN**. Perfeccionará aún más los datos sintéticos, centrándose en las muestras desafiantes (random_state=42)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8J90TAkQF8wm"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong> Realiza el análisis de balance de clases.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1734535414439,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "IPWZSnoTZun4",
    "outputId": "732eab45-2933-4936-dd3f-a1fa946429eb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JChzUP4JsI2c"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong> Crea un nuevo DataFrame para los datos remuestreados.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1734535414739,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "x52o7IPFbMYl",
    "outputId": "36f7aec7-fa87-4b2e-a291-048b7970074e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx1WePqusbhy"
   },
   "source": [
    "### **2. Reducción de Dimensionalidad (1 punto)**\n",
    "\n",
    "En esta parte de la PEC, utilizaremos **Análisis de Componentes Principales (PCA)** para mejorar la información de los pacientes diabéticos con el objetivo de facilitar la separación en el modelo de clasificación. Nuestro objetivo es garantizar que el modelo PCA capture patrones útiles para distinguir mejor a los pacientes diabéticos de los no diabéticos.\n",
    "\n",
    "**Riesgos de Overfitting y Cómo Evitarlos:**\n",
    "\n",
    "Cuando construimos el modelo PCA solo con pacientes diabéticos, puede existir el riesgo de que los componentes principales capturen patrones específicos de este grupo y no se generalicen bien para los pacientes no diabéticos. Para mitigar este riesgo, seguiremos un enfoque robusto con **validación cruzada**, el cual:\n",
    "\n",
    "1. **Reduce el sobreajuste**, evaluando la estabilidad de los componentes principales a través de diferentes particiones de datos de pacientes diabéticos.\n",
    "2. **Garantiza una mejor generalización**, ya que seleccionamos un conjunto estable de componentes mediante la **promediación de las cargas** de los componentes principales a través de los diferentes pliegues (folds) de la validación cruzada.\n",
    "\n",
    "### **Proceso Recomendado**\n",
    "\n",
    "1. **Preparación:** Se separan los pacientes diabéticos para el entrenamiento del PCA. Divide los datos diabéticos en entrenamiento/validación (80%) y pruebas (20%), random_state=42.\n",
    "2. **Normalización y Validación Cruzada para el PCA:** Utilizamos validación cruzada (n_splits=5, shuffle=True, random_state=42) para normalizar los datos y evaluar la consistencia de los componentes principales.\n",
    "3. **Promediación de los Componentes Principales:** Se promedian las cargas de los componentes principales para obtener un conjunto estable.\n",
    "4. **Proyección de los Datos Restantes:** Utilizamos los componentes estables para proyectar tanto los datos de test de los pacientes diabéticos como los datos de los pacientes no diabéticos.\n",
    "5. **Creación del Conjunto de Entrenamiento para Clasificación:** El conjunto de datos proyectado se utiliza como entrada para los modelos de clasificación.\n",
    "\n",
    "Este enfoque garantiza que el modelo PCA no sobreajuste a los pacientes diabéticos utilizados para construirlo, y nos permite utilizar descriptores coherentes para todo el conjunto de datos. Esto mejora la robustez del modelo de clasificación, minimizando el riesgo de sesgo y mejorando la separación de los pacientes en base a sus características proyectadas.\n",
    "\n",
    "- 2.1. Preparación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MerSr49ci7D"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong> Se separan los pacientes diabéticos para el entrenamiento del PCA. Divide los datos diabéticos en entrenamiento/validación (80%) y pruebas (20%), random state=42.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1734535414739,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "fQwMTrudsb4S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_exXotfGTHmp"
   },
   "source": [
    "- 2.2. Normalización y construcción del modelo PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vK8V4NebdRuZ"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong> Se normalizan los datos y se crea el modelo de los componentes principales con el conjunto de pacientes de entrenamiento del paso anterior (diabéticos) con el 95% de varianza retenida.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734535414739,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "8NysrPVoXHKB",
    "outputId": "598b72c1-e1f2-4a5f-9650-77f981669ebd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7MTF-jnBoMV"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong> Realice las gráficas que considere necesarias.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "executionInfo": {
     "elapsed": 1902,
     "status": "ok",
     "timestamp": 1734535417891,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "8_KxvJhtbLPW",
    "outputId": "8107d543-15b0-44d8-a12d-036034e12e08"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0NBYmIwFyuM"
   },
   "source": [
    "- 2.3. Proyección de los Datos Restantes\n",
    "\n",
    "En este punto, ya hemos construido el modelo PCA utilizando solo los datos de los pacientes diagnosticados con diabetes. Ahora, para poder comparar el rendimiento de nuestros clasificadores de manera consistente, necesitamos proyectar **todas** las muestras. Tanto los datos escalados de los pacientes con diabetes (restante 20%) como los de los pacientes sin diabetes, sobre este mismo modelo PCA.\n",
    "\n",
    "##### **¿Por qué proyectar todos los datos sobre el mismo modelo PCA?**\n",
    "\n",
    "1. **Consistencia de los descriptores**:\n",
    "   - Al proyectar todos los datos sobre el mismo modelo PCA, obtenemos un conjunto de descriptores uniformes (los componentes principales) para todos los pacientes, independientemente de su diagnóstico. Esto es clave para que los clasificadores trabajen con las mismas variables de entrada.\n",
    "\n",
    "2. **Reducción de la dimensionalidad**:\n",
    "   - Utilizar los componentes principales como variables de entrada reduce el número de dimensiones, lo que facilita el entrenamiento de los modelos y reduce el riesgo de overfitting.\n",
    "\n",
    "3. **Mejora de la generalización**:\n",
    "   - Al usar descriptores PCA, que son las combinaciones lineales de las variables originales más informativas, se mejora la capacidad del modelo para generalizar a nuevos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCnVGlC4eSXc"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong>\n",
    "Utilizamos el modelo creado en el paso anterior para proyectar tanto los datos de test de los pacientes diabéticos (20% restante) como los datos de los pacientes no diabéticos.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734535417891,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "BptQgDj6kP73",
    "outputId": "f6b0367f-5986-42b8-f4db-eb0e02ef20ae"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gqM-Zy-A7dP"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong> Realice las gráficas que considere necesarias. Ayuda:\n",
    "Realice la gráfica en 2D de las dos primeras componentes principales (o 3D para las tres primeras). Incluye los datos utilizados para entrenar el modelo (diabéticos 80%), el 20% restante de diabéticos y los no diabéticos. Utilice colores distintos para cada grupo.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1734535417891,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "QosKA-1SG7PE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIEwShmYrEu8"
   },
   "source": [
    "- 2.4. Creación del Conjunto de Entrenamiento para Clasificación\n",
    "\n",
    "Al trabajar con modelos de PCA utilizando la librería `scikit-learn`, es importante entender que el objeto del PCA (`pca_final`) **no guarda automáticamente los componentes principales asociados a las muestras transformadas**. El PCA solo mantiene los componentes del modelo (es decir, las combinaciones lineales de las variables originales) y la información de la varianza explicada.\n",
    "\n",
    "Por ello, si deseáis conservar los **valores de los componentes principales (scores)** asociados a cada muestra transformada para su uso futuro, debéis hacerlo **manualmente**, creando un DataFrame separado. Esto os permitirá:\n",
    "\n",
    "1. **Reutilizar los datos**: Podréis cargarlos directamente en el futuro sin tener que repetir el cálculo del PCA.\n",
    "2. **Asegurar la consistencia**: Evitad diferencias si el conjunto de datos original cambia o si se añaden nuevas muestras.\n",
    "3. **Preparar los datos para el análisis**: Podéis combinar los scores con otras variables o utilizarlos directamente en modelos de clasificación.\n",
    "\n",
    "Consideraciones finales:\n",
    "- Recordad que este proceso debe repetirse para cualquier conjunto de datos que deseéis proyectar en el modelo PCA (diabetic_test_data, non_diabetic_data).\n",
    "- Esta separación permite mantener el modelo PCA enfocado únicamente en transformaciones y conservar los scores como datos procesados.\n",
    "\n",
    "Esta particularidad puede parecer poco intuitiva al principio, pero asegura que el modelo se mantenga modular y fácil de utilizar para otras transformaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGQ3IwodYG3x"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong>\n",
    "Agrupa en un solo conjunto de datos la proyección de los datos de train de los pacientes no diabéticos (los que ya se han utilizado para entrenar al PCA), el 20% de los datos de test de los pacientes diabéticos y todos los datos de los pacientes no diabéticos.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong> </strong>\n",
    "El conjunto de datos resultante contiene:\n",
    "<ol>\n",
    " <li> Una columna para cada componente principal (\"PC1\", \"PC2\", ..., \"PCn\").\n",
    " <li> Una columna \"Outcome\" para identificar si son muestras de diabéticos o no.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1734535419289,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "X6nLTnsFRuqS",
    "outputId": "f10e37cc-33d6-49ca-eae9-7480f02e1606"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmN3XW0vH9X9"
   },
   "source": [
    "### 3. Entrenamiento y Evaluación de Modelos Base (2.5 puntos)\n",
    "\n",
    "Se formarán cuatro modelos diferentes:\n",
    "- 1. Regresión Logística\n",
    "- 2. Árbol de Decisión\n",
    "- 3. Bosque Aleatorio (Random Forest)\n",
    "- 4. SVM\n",
    "\n",
    "y cada modelo será entrenado utilizando los dos grupos de:\n",
    "- Las características originales\n",
    "- Las características transformadas de PCA.\n",
    "\n",
    "##### 3.1 Entrenamiento\n",
    "\n",
    "3.1.1. Características originales\n",
    "\n",
    "Pasos a seguir para las entradas de las características originales:\n",
    "\n",
    "- 1. Reúne las características originales en un solo dataframe llamado X y otro llamado y para la salida u outcome.\n",
    "\n",
    "- 2. Asigna las etiquetas de clase: Asigna 1 para muestras diabéticas y 0 para muestras no diabéticas.\n",
    "\n",
    "- 3. Divide los datos: Asegúrate de dividir el conjunto de datos combinado en conjuntos de entrenamiento (80%) y prueba si no lo has hecho ya. Esto evita la fuga de información de las pruebas al entrenamiento.\n",
    "\n",
    "- 4. Entrenamiento y evaluación de modelos de clasificación: Utiliza el conjunto de datos para entrenar modelos que puedan separar las clases diabéticas y no diabéticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMsQqnY5bvkF"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong> Para las características originales, prepara la entrada X y salida/outcome y para los clasificadores.\n",
    "Divide el conjunto de datos en 80%-20% para entrenamiento y prueba.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1734535419289,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "JVZCzcJWKR0_",
    "outputId": "10f4a91f-35fb-42e7-ee62-619e73c6537f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RamtH-jgTMyi"
   },
   "source": [
    "3.1.2. Entradas de los componentes principales\n",
    "\n",
    "Este es el momento en el que utilizarás los componentes principales que has almacenado anteriormente de PCA. Pasos a seguir para las entradas de los componentes principales:\n",
    "\n",
    "- 1. Combina los componentes principales diabéticos y no diabéticos: Combina los componentes principales de los datos diabéticos (entrenamiento y prueba) y no diabéticos en un único conjunto de datos para la clasificación.\n",
    "\n",
    "- 2. Asigna las etiquetas de clase: Asigna 1 para muestras diabéticas y 0 para muestras no diabéticas.\n",
    "\n",
    "- 3. Divide los datos combinados: Asegúrate de dividir el conjunto de datos combinado en conjuntos de entrenamiento (80%) y prueba si no lo has hecho ya. Esto evita la fuga de información de las pruebas al entrenamiento.\n",
    "\n",
    "- 4. Entrenamiento y evaluación de modelos de clasificación: Utiliza el conjunto de datos para entrenar modelos que puedan separar eficazmente las clases diabéticas y no diabéticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMeNXBZ-ceIX"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong> Para las características transformadas de PCA, prepara la entrada X y la salida/outcome y para los clasificadores.  \n",
    "Divide el conjunto de datos en un 80% para entrenamiento y un 20% para prueba.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734535419289,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "Rq9picZXMU0W",
    "outputId": "315810b0-e612-4330-a650-aee10230071b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGjKIV9TJREl"
   },
   "source": [
    "- 3.2. Entrenamiento de los modelos de clasificación con las variables originales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKiHOse6hYte"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong> Entrena modelos base con las variables originales como descriptores y evalúa los modelos utilizando métricas de exactitud, sensibilidad, especificidad, ROC-AUC y análisis de la matriz de confusión.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2738
    },
    "executionInfo": {
     "elapsed": 2767,
     "status": "ok",
     "timestamp": 1734535422052,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "i1dCQEvWJKQH",
    "outputId": "c836594c-23e7-4bf2-b540-de9221ced9da"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aLz1vetMV3z"
   },
   "source": [
    "- 3.3. Entrenamiento de los modelos de clasificación con las variables transformadas por los componentes principales (PCs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1AxzmIq7wDbS"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong> Entrena modelos base con los componentes principales (PCs) como descriptores y evalúa los modelos utilizando métricas de exactitud, sensibilidad, especificidad, ROC-AUC y análisis de la matriz de confusión.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3085
    },
    "executionInfo": {
     "elapsed": 4822,
     "status": "ok",
     "timestamp": 1734535426872,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "uTqgCou_DgAR",
    "outputId": "1b3b01f4-329a-4453-a0b3-f4000ec38c2c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bfEuHcbEIA6"
   },
   "source": [
    "- 3.4 Análisis de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3FMy_JMNtJW"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Análisis:</strong> Analice los resultados utilizando las variables originales como entradas a las herramientas de clasificación y los resultados utilizando los principales componentes o variables latentes como entradas a las mismas herramientas de clasificación.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gk98W7juEm7G"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1AMZaCwEKDu"
   },
   "source": [
    "### **4. Técnicas Avanzadas de Ensemble (3 puntos)**\n",
    "\n",
    "- 4.1. Implemente y evalúe técnicas de ensemble como Bagging, Boosting, Stacking y Cascading utilizando las variables originales.\n",
    "- 4.2. Repita la implementación con los componentes principales como descriptores.\n",
    "- 4.3. Compare el rendimiento de cada método y analice los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3E0aP7_CJ-c"
   },
   "source": [
    "Para aplicar el ensemble learning, proponemos seguir los siguientes pasos:\n",
    "\n",
    "---\n",
    "\n",
    "**1. Clase `CascadingClassifier`**\n",
    "\n",
    "###### **Propósito:**\n",
    "- Implementa una técnica personalizada de aprendizaje en ensamblado donde las predicciones de un primer modelo (`base_model1`) se añaden como características adicionales a los datos de entrada para un segundo modelo (`base_model2`).\n",
    "\n",
    "###### **Componentes clave:**\n",
    "- **Método `__init__`:**\n",
    "  - Inicializa el clasificador con dos modelos base.\n",
    "- **Método `fit`:**\n",
    "  - Entrena el `base_model1` con las características de entrada (`X`) y las etiquetas (`y`).\n",
    "  - Genera las predicciones del `base_model1` y las añade como una nueva columna a las características de entrada.\n",
    "  - Entrena el `base_model2` con este conjunto de datos aumentado.\n",
    "- **Método `predict`:**\n",
    "  - Utiliza el `base_model1` entrenado para predecir las etiquetas de los datos de entrada.\n",
    "  - Aumenta las características de entrada con estas predicciones y las pasa al `base_model2` para obtener las predicciones finales.\n",
    "- **Método `predict_proba`:**\n",
    "  - Similar a `predict`, pero devuelve las probabilidades de clase para los datos de entrada.\n",
    "\n",
    "###### **Librerías y técnicas clave:**\n",
    "- **`np.hstack`:** Combina arrays por columnas para añadir las predicciones como características.\n",
    "- **`BaseEstimator` y `ClassifierMixin`:** Garantizan la compatibilidad con los pipelines y métodos de evaluación de Scikit-learn.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Función `evaluate_ensemble`**\n",
    "\n",
    "###### **Propósito:**\n",
    "- Evalúa el rendimiento de los modelos ensemble utilizando métricas como el accuracy, la sensibilidad, la especificidad y el ROC-AUC. También genera una matriz de confusión y la curva ROC.\n",
    "\n",
    "###### **Visualización:**\n",
    "- Utiliza `RocCurveDisplay` para trazar la curva ROC.\n",
    "- Mejora la interpretabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diCKBgHHAT-W"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong>\n",
    "Aplica los pasos anteriormente descritos para obtener los modelos y realizar el testing de las técnicas de Bagging, Boosting, Stacking y Cascading, tanto para las características originales como para los componentes principales:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4808
    },
    "executionInfo": {
     "elapsed": 11276,
     "status": "ok",
     "timestamp": 1734535438145,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "8tuKx4yOEL9V",
    "outputId": "b7dfb1d2-1764-4e20-eb17-b849d8cbb31f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkDuJMfbMeHr"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Análisis:</strong> Compara el rendimiento de cada método utilizando las métricas calculadas.\n",
    "Discute cómo se comporta cada método con las variables originales en comparación con los datos transformados por PCA. Analiza cómo el PCA afecta el rendimiento de cada método de ensemble.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgFnnN_oiOry"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKsU3uyj71fc"
   },
   "source": [
    "### **5. Convolutional Neural Network para Datos Tabulares (1 punto + 1 adicional)**\n",
    "\n",
    "5.1 ¿Qué es una CNN?\n",
    "**CNN** significa **Red Neuronal Convolucional** (en inglés, **Convolutional Neural Network**). Es un tipo de red neuronal profunda utilizada principalmente en tareas de visión por computador, aunque también se aplica en otros campos como el procesamiento del lenguaje natural y las series temporales.\n",
    "\n",
    "Una CNN es especialmente efectiva para analizar **imágenes** y **datos espaciales** porque puede identificar automáticamente **patrones, bordes y características** en diferentes niveles de abstracción. Es decir, aprende a detectar características simples como líneas o colores en las primeras capas y características más complejas (caras, objetos, etc.) en capas más profundas.\n",
    "\n",
    "**Componentes de una CNN:**\n",
    "1. **Capa Convolucional (Convolutional Layer):**\n",
    " Aplica filtros a la imagen de entrada para extraer características como bordes, texturas o formas.\n",
    "\n",
    "2. **Función de Activación (Activation Function):**\n",
    " Introduce no linealidad en el modelo. La más utilizada es **ReLU (Rectified Linear Unit)**, que elimina valores negativos.\n",
    "\n",
    "3. **Capa de Pooling (Pooling Layer):**\n",
    " Reduce la dimensionalidad de las características extraídas, disminuyendo el tiempo de cálculo y evitando el sobreajuste. **max-pooling** es el más común, ya que selecciona el valor máximo dentro de una región.\n",
    "\n",
    "4. **Capas Densas (Fully Connected Layers):**\n",
    " Conectan todas las neuronas previas y generan la salida final, como la clasificación de una imagen (por ejemplo, perro vs. gato).\n",
    "\n",
    "---\n",
    "\n",
    "### **Ejemplo de Aplicación:**\n",
    "- **Clasificación de Imágenes:** Identificación de objetos en imágenes (reconocimiento facial, vehículos, etc.).\n",
    "- **Detección de Anomalías:** Reconocimiento de patrones anómalos en imágenes médicas o de seguridad.\n",
    "- **Reconocimiento de Texto:** Detección de caracteres o texto manuscrito.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "5.2. Adaptación de los datos para utilizar una CNN\n",
    "\n",
    "En este apartado, transformaremos los datos tabulares en una forma que pueda ser procesada por un modelo personalizado, como un Custom CNN. Esto implica representar los datos tabulares como \"imágenes\" (matrices en 2D o 3D) para cumplir con los requisitos de entrada del modelo.\n",
    "\n",
    "---\n",
    "\n",
    "5.2.1. ¿Por qué es necesario transformar los datos tabulares?\n",
    "Los modelos convolucionales están diseñados para trabajar con datos en forma de matrices (altura, anchura, canales), habitualmente para procesar imágenes. En el caso de nuestros datos:\n",
    "- Los datos originales tienen **8 características** (por ejemplo, `Glucose`, `BMI`, etc.).\n",
    "- Los datos PCA tienen **7 componentes principales**, que son combinaciones lineales de las características originales.\n",
    "\n",
    "Dado que estas características son unidimensionales, es necesario transformarlas para que el modelo pueda procesarlas como \"imágenes artificiales\".\n",
    "\n",
    "---\n",
    "\n",
    "5.2.2. ¿Cómo se transforma una matriz unidimensional en una \"imagen\"?\n",
    "\n",
    "Para convertir los datos tabulares en \"imágenes\", debemos:\n",
    "\n",
    "1. **Decidir la forma de entrada (`input_shape`):**\n",
    " - Los datos originales con **8 características** se pueden reorganizar en una matriz de **\\(2 x 4 x 1\\)** (2 filas, 4 columnas y 1 canal).\n",
    " - Los datos PCA con **7 componentes principales** se pueden reorganizar en una matriz de **\\(7 x 1 x 1\\)**.\n",
    "\n",
    "2. **Validar la forma de los datos:**\n",
    " - El número total de características debe coincidir con el producto \\( altura x anchura x canales \\).\n",
    " - Por ejemplo, para los datos originales, \\(2 x 4 x 1 = 8 \\), que corresponde al número de características.\n",
    "\n",
    "3. **Aplicar la transformación:**\n",
    " - Reorganizamos cada muestra para que tenga la forma adecuada mediante un código personalizado.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJiFPegDTrWy"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong>\n",
    "Aplica los pasos descritos anteriormente para transformar los datos tabulares en imágenes:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1734535438145,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "lgDQsQjl89Sm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_zcKySM9GwU"
   },
   "source": [
    "- 5.3 Transformación de los datos\n",
    "\n",
    "1. **Datos originales (8 características):** Los datos originales con 8 características se pueden reorganizar en una matriz de (2 x 4 x 1) (2 filas, 4 columnas y 1 canal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7rtzkLlUa6d"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong>\n",
    "Reorganiza los datos en una matriz de (2x4x1):\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1734535438145,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "JjhFF1hq9a8T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JejEev9u9ihp"
   },
   "source": [
    "2. **Datos PCA (7 componentes principales):**  \n",
    "Los datos PCA con 7 componentes principales se pueden reorganizar en una matriz de (7 x 1 x 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5L6vpYbUbkf"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong>  \n",
    "Reorganiza los datos en una matriz de (7x1x1):\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734535438145,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "BFR8Jfmp-Fgv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpGixdgWVEht"
   },
   "source": [
    "- **5.4. Conversión de datos a float32**\n",
    "\n",
    "**¿Por qué es necesario convertir los datos a `float32`?**\n",
    "\n",
    "En el ámbito del aprendizaje automático y el procesamiento de datos, es habitual que sea necesario convertir los datos al formato `float32`. Pros:\n",
    "\n",
    "---\n",
    "\n",
    "**Eficiencia de memoria**\n",
    "- **Reducción del uso de memoria**: El formato `float32` utiliza 4 bytes de memoria, mientras que `float64` (el formato predeterminado en muchas librerías como NumPy o Pandas) utiliza 8 bytes. En conjuntos de datos grandes, esta diferencia puede reducir significativamente el consumo de memoria.\n",
    "- **Adaptabilidad para GPUs**: Las GPUs suelen trabajar con `float32` de manera nativa. Utilizar este formato evita un uso innecesario de memoria y mejora la eficiencia computacional.\n",
    "\n",
    "---\n",
    "\n",
    "**Optimización del rendimiento**\n",
    "- **Cálculos más rápidos**: Los cálculos con `float32` son más rápidos que con `float64`, especialmente en GPUs, ya que muchas herramientas de aprendizaje profundo (como TensorFlow o PyTorch) están optimizadas para `float32`.\n",
    "- **Tiempo de transferencia reducido**: Transferir datos entre CPU y GPU es más rápido cuando los datos están en formato `float32`, gracias al menor volumen de datos.\n",
    "\n",
    "---\n",
    "\n",
    "**Evitar problemas de compatibilidad**\n",
    "- **Requisitos de las herramientas**: Muchas herramientas de aprendizaje automático, como TensorFlow o Keras, esperan que los datos de entrada estén en formato `float32`. Si se utiliza `float64`, se pueden generar advertencias o errores que obligarán a hacer la conversión posteriormente.\n",
    "- **Modelos preentrenados**: La mayoría de los modelos preentrenados y operaciones en aprendizaje profundo están diseñados para trabajar con `float32`. Esto asegura la compatibilidad y evita desajustes entre tipos de datos.\n",
    "\n",
    "---\n",
    "\n",
    "**Impacto mínimo en la precisión**\n",
    "- **Precisión suficiente**: Para la mayoría de tareas de aprendizaje automático, la precisión que ofrece `float32` es más que suficiente. Aunque `float64` proporciona una precisión más alta, esta normalmente no es necesaria en aplicaciones prácticas.\n",
    "- **Control de errores**: El formato `float32` ayuda a mitigar problemas como desbordamientos o subdesbordamientos de valores, que pueden ser más probables con `float64`.\n",
    "\n",
    "---\n",
    "\n",
    "**Buenas prácticas en la industria**\n",
    "- **Consistencia**: Mantener el mismo tipo de datos en toda la pipeline (entrada, pesos del modelo, salidas) evita comportamientos inesperados o incompatibilidades durante los cálculos.\n",
    "- **Estándar**: La mayoría de librerías y herramientas de aprendizaje automático utilizan `float32` como formato predeterminado. Esto hace que este formato sea un estándar para garantizar la compatibilidad.\n",
    "\n",
    "---\n",
    "\n",
    "**¿Cuándo no es necesario convertir a `float32`?**\n",
    "- **Requisitos de alta precisión**: Si la aplicación requiere cálculos muy precisos (por ejemplo, simulaciones científicas), podría ser más adecuado utilizar `float64`.\n",
    "- **Conjuntos de datos pequeños**: Si el conjunto de datos es pequeño y el consumo de memoria no es un problema, la conversión puede no ser imprescindible.\n",
    "\n",
    "---\n",
    "\n",
    "Por tanto, a la hora de preparar los datos para una pipeline de aprendizaje automático, **debes convertirlos a `float32` para mejorar el rendimiento, reducir el consumo de memoria y garantizar la compatibilidad con las herramientas modernas.** Esto es especialmente importante si estás trabajando con conjuntos de datos grandes o entrenando modelos en GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgRh-TSjUsLF"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong>  \n",
    "Convierte los datos originales y los componentes principales (PCs) a `float32`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734535438145,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "WWu3Xhk_WG-1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEbFbe78-OB6"
   },
   "source": [
    "- Errores comunes y cómo evitarlos  \n",
    "1. **Forma de entrada incorrecta:**  \n",
    "   - Si el número de características no coincide con el producto de la forma de entrada especificada, aparecerá un error.  \n",
    "   - **Solución:** Comprueba que el número de características \\(n\\) = \\(altura x anchura x canales\\).  \n",
    "\n",
    "2. **Transformación repetida:**  \n",
    "   - Transformar los datos repetidamente puede generar errores.  \n",
    "   - **Solución:** Utiliza solo los datos transformados (por ejemplo, `X_train_original_reshaped`) en entrenamientos posteriores.  \n",
    "\n",
    "3. **Diferencias en las dimensiones entre datos de entrenamiento y test:**  \n",
    "   - Si los datos de entrenamiento y test tienen dimensiones diferentes, ResNet50 no podrá procesarlos.  \n",
    "   - **Solución:** Asegúrate de que la transformación se aplica de manera consistente a todos los datos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9a7ij2YW6bk"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong>\n",
    "Antes de entrenar el modelo, asegúrate de que los datos tienen la forma correcta:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734535438145,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "rbclq2DZB026",
    "outputId": "7d096642-e84f-40f8-f8c5-c76c655720de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQOqXZEuOSzp"
   },
   "source": [
    "- 5.5. Entrena el modelo utilizando los datos preprocesados y compara el rendimiento con los métodos de ensemble.\n",
    "\n",
    "Una vez transformados los datos, entrena y evalua la CNN:\n",
    "\n",
    "Args:\n",
    "- X_train: Datos de entrenamiento (ya transformados).\n",
    "- X_test: Datos de prueba (ya transformados).\n",
    "- y_train: Etiquetas de entrenamiento.\n",
    "- y_test: Etiquetas de prueba.\n",
    "- input_shape: Forma de los datos de entrada.\n",
    "- dataset_type: Cadena que indica si el conjunto de datos es \"original\" o \"pca\".\n",
    "- Imprime: métricas de evaluación y dibuja la curva ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-O9cldSXRcD"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong>\n",
    "Crea la función para una CNN personalizada para los datos tabulares remodelados en pequeñas estructuras similares a imágenes en 2D.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1734535438145,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "8AxWTlwmLSnj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfAKC4yrEU4k"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong>\n",
    "Crea la función para entrenar y evaluar un modelo CNN personalizado para datos tabulares remodelados como imágenes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1734535438145,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "MIKmVIRMpSME"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_w6ZayKtCHcE"
   },
   "source": [
    "- 5.6. Evaluación de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YR9KJAfvE2Ff"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong>\n",
    "Evalúe el modelo con los datos originales utilizando exactitud, sensibilidad, especificidad, ROC-AUC y matriz de confusión.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1553
    },
    "executionInfo": {
     "elapsed": 13057,
     "status": "ok",
     "timestamp": 1734535451199,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "y3_dHGdCPnwH",
    "outputId": "b2ddd370-b3ff-43fb-b6bc-dfb196be99db"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PBE-bUIFPQ0"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong>\n",
    "Evalúe el modelo con los datos con PCA utilizando exactitud, sensibilidad, especificidad, ROC-AUC y matriz de confusión.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1553
    },
    "executionInfo": {
     "elapsed": 3919,
     "status": "ok",
     "timestamp": 1734535455114,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "W4fpBHpxQNaI",
    "outputId": "674db090-720b-4ccf-b2ca-3f381fe4225d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSR46n5zFkL1"
   },
   "source": [
    "- 5.7. Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxzWFEUZFfhA"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Análisis:</strong> Analiza los resultados de las dos implementaciones del modelo CNN personalizado, una con datos originales y otra con datos transformados con PCA.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ewks-gV5Owas"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dDEbYF_OCd8"
   },
   "source": [
    "- 5.8. **Comparativa entre CNN personalizada y métodos de ensemble**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJGVHSkOOZnR"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Análisis:</strong> Compara los resultados obtenidos con la CNN personalizada y los métodos de ensemble (Bagging, Boosting, Stacking y Cascading), tanto con los datos originales como con los datos transformados mediante PCA. Identifica qué métodos son más efectivos en función de las métricas clave: Accuracy, Sensitivity, Specificity y ROC-AUC.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jN1KHo5YQwcK"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.9. **(Opcional) Transfer Learning (1 punto adicional)**\n",
    "\n",
    "**¿Qué es el *Transfer Learning*?** \n",
    "\n",
    "El *Transfer Learning*, o aprendizaje por transferencia, es una técnica avanzada dentro del campo de la inteligencia artificial y el aprendizaje automático. La idea principal es sencilla pero muy poderosa: aprovechar el conocimiento adquirido por un modelo cuando ha sido entrenado en una tarea para aplicarlo a otra tarea diferente pero relacionada.\n",
    "\n",
    "##### Metáfora para entenderlo\n",
    "Imagina que aprendes a tocar el piano. Una vez has aprendido las bases, como leer partituras o coordinar las manos, aprender a tocar otro instrumento, como el violín, será más fácil porque muchas habilidades que has adquirido ya son aplicables. Esto es exactamente lo que hace el *Transfer Learning* en el ámbito de los modelos de aprendizaje profundo.\n",
    "\n",
    "---\n",
    "\n",
    "**¿Cómo funciona?**\n",
    "1. **Modelo preentrenado**:\n",
    "   - En el *Transfer Learning*, se comienza con un modelo ya entrenado en una gran cantidad de datos generales (como imágenes de miles de categorías diferentes).\n",
    "   - Este modelo ha aprendido patrones generales (por ejemplo, identificar líneas, formas y texturas en imágenes).\n",
    "\n",
    "2. **Transferencia de conocimiento**:\n",
    "   - Se reutilizan las primeras capas del modelo preentrenado, que contienen este conocimiento general.\n",
    "   - Solo es necesario ajustar (o añadir) las capas finales para que el modelo pueda especializarse en la nueva tarea específica.\n",
    "\n",
    "3. **Entrenamiento con datos específicos**:\n",
    "   - Con un conjunto más pequeño de datos específicos de la tarea (como imágenes de pacientes con o sin diabetes), el modelo se entrena para refinar el conocimiento y adaptarse.\n",
    "\n",
    "---\n",
    "\n",
    "**¿Por qué utilizar el *Transfer Learning*?**\n",
    "1. **Ahorro de tiempo y recursos**:\n",
    "   - No es necesario entrenar un modelo desde cero, ya que el modelo preentrenado ya ha realizado gran parte del trabajo de aprendizaje.\n",
    "   - Esto reduce significativamente el tiempo y los costos computacionales.\n",
    "\n",
    "2. **Mayor rendimiento con datos limitados**:\n",
    "   - Si solo disponemos de un conjunto pequeño de datos específicos, el *Transfer Learning* ayuda a evitar problemas como el sobreajuste (*overfitting*), aprovechando el conocimiento previo.\n",
    "\n",
    "3. **Resultados robustos**:\n",
    "   - Los modelos preentrenados ya han sido probados con grandes conjuntos de datos, lo que garantiza una base sólida y generalizable para trabajar.\n",
    "\n",
    "---\n",
    "\n",
    "##### Ejemplo práctico\n",
    "Supongamos que queremos clasificar si una imagen muestra a un paciente con diabetes o no. Podemos utilizar un modelo preentrenado como ResNet50 (que ha aprendido a reconocer patrones generales de imágenes) y adaptarlo a nuestra tarea, sin necesidad de entrenarlo desde cero.\n",
    "\n",
    "El *Transfer Learning* permite enfocarnos en nuestra tarea específica sin perder tiempo construyendo y entrenando un modelo completamente nuevo. Es como subirse a los hombros de un gigante para llegar más lejos.\n",
    "\n",
    "---\n",
    "\n",
    "Con este conocimiento básico, ya podemos entrar en detalle sobre cómo implementar el *Transfer Learning* y aprovecharlo para mejorar nuestros resultados. Los pasos serán los siguientes:\n",
    "\n",
    "- Adaptar un modelo de red neuronal preentrenado (ResNet50) para datos tabulares.\n",
    "- Entrenar el modelo utilizando los datos preprocesados y comparar el rendimiento con los métodos de ensemble.\n",
    "- Evaluar el modelo utilizando exactitud, sensibilidad, especificidad, ROC-AUC y matriz de confusión.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJxQPKVlSsS4"
   },
   "source": [
    "## **6. Optimización del Modelo y Ajuste de Hiperparámetros (2 puntos)**\n",
    "\n",
    "- 6.1. Ajuste de hiperparámetros con GridSearchCV para el mejor modelo de ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRY-tZeIQihF"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong>\n",
    "Seleccione el modelo de ensemble con mejor rendimiento (por ejemplo, Stacking o Bagging). Defina una cuadrícula de hiperparámetros relevantes. Por ejemplo: Para Bagging: Número de estimadores (n_estimators), tamaño máximo de muestras (max_samples); Para Stacking: Modelos base y parámetros asociados a los clasificadores meta. Utilice GridSearchCV para explorar las combinaciones posibles de los hiperparámetros y seleccionar la mejor configuración.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 40842,
     "status": "ok",
     "timestamp": 1734535495953,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "HDSyTNGCEPVG",
    "outputId": "33f84c9f-d5c4-4adc-f209-708deeeebf8e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFgphcJFJ4AH"
   },
   "source": [
    "- 6.2. Evaluación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZeY95uRRnDh"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Implementación:</strong>\n",
    "Aplique el modelo con los mejores hiperparámetros al conjunto de test. Compare las métricas del modelo optimizado con el modelo inicial.\n",
    "</div>\n",
    "\n",
    "**Consideraciones finales**\n",
    "- La sintonización de hiperparámetros a menudo proporciona mejoras significativas, pero puede ser computacionalmente costosa. Priorice los parámetros más influyentes.\n",
    "- Las métricas de evaluación del conjunto de test son clave para determinar si la optimización ha mejorado el modelo de manera generalizada.\n",
    "- Documente los hiperparámetros seleccionados, los cambios en las métricas y cualquier observación relevante para justificar sus decisiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 27901,
     "status": "ok",
     "timestamp": 1734535523851,
     "user": {
      "displayName": "Magda Liliana Ruiz Ordóñez",
      "userId": "01162134209636227374"
     },
     "user_tz": -60
    },
    "id": "g9M76YWtTNGI",
    "outputId": "cc942523-4b88-492e-914c-5700311907a6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSCc5XxFTY3f"
   },
   "source": [
    "- 6.4. Análisis de los modelos optimizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVlWjeZbTVkN"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Análisis:</strong> Valore el impacto de los hiperparámetros optimizados en el conjunto de test comparando con los resultados obtenidos antes de la optimización.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIXJblmdbDnU"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxH-o9zTbOw7"
   },
   "source": [
    "Adicionalmente es importante remarcar:\n",
    "\n",
    "**Importancia de la Sensibilidad y la Especificidad en Datos Médicos:**\n",
    "\n",
    "En el contexto médico, la **sensibilidad** y la **especificidad** son métricas cruciales que miden la capacidad de una prueba diagnóstica para identificar correctamente los casos positivos y negativos, respectivamente. Estas métricas son especialmente importantes porque ayudan a prevenir errores diagnósticos que podrían llevar a tratamientos incorrectos o falta de tratamiento.\n",
    "\n",
    "- **Sensibilidad** (también conocida como tasa de verdadero positivo): Mide la proporción de positivos reales que son correctamente identificados por el modelo. Una alta sensibilidad es crucial en condiciones médicas donde no detectar una enfermedad (un falso negativo) podría tener consecuencias graves para el paciente. Por ejemplo, en el diagnóstico de cáncer, una alta sensibilidad es esencial para asegurar que casi todos los pacientes con la enfermedad sean identificados para un tratamiento precoz.\n",
    "\n",
    "- **Especificidad** (también conocida como tasa de verdadero negativo): Mide la proporción de negativos reales que son correctamente identificados. Una alta especificidad es importante para evitar falsos positivos, que podrían llevar a pacientes sin la enfermedad a someterse a procedimientos invasivos o estresantes innecesarios. Por ejemplo, en el cribado de enfermedades cardíacas, una alta especificidad reduce el número de pacientes que recibirán diagnósticos erróneos de condiciones que no tienen.\n",
    "\n",
    "**Relación entre Sensibilidad y Especificidad:**\n",
    "\n",
    "La relación entre sensibilidad y especificidad a menudo involucra un **compromiso**; optimizar un modelo para mejorar la sensibilidad generalmente reducirá su especificidad y viceversa. Esto se debe a que el aumento de la sensibilidad implica bajar el umbral para clasificar un resultado como positivo, lo que incrementa el número de falsos positivos y disminuye la especificidad. A la inversa, aumentar la especificidad solo aumenta el umbral, lo que puede llevar a más falsos negativos y disminuir la sensibilidad.\n",
    "\n",
    "**Aplicaciones en el Mundo Real:**\n",
    "\n",
    "La selección de un modelo en un entorno médico depende de la enfermedad específica y del contexto del cribado o diagnóstico. En enfermedades donde las consecuencias de no detectar un caso positivo son graves, como en el cáncer o infecciones graves, se puede preferir un modelo con alta sensibilidad. En cambio, en condiciones donde un diagnóstico falso positivo podría llevar a tratamientos innecesarios o perjudiciales, se preferirá un modelo con alta especificidad.\n",
    "\n",
    "La comprensión de este equilibrio y su correcta aplicación son esenciales para desarrollar herramientas diagnósticas que no solo sean técnicamente competentes sino también éticamente responsables, asegurando que los pacientes reciban el diagnóstico más preciso posible con las mínimas repercusiones negativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBkUI8h8b0To"
   },
   "outputs": [],
   "source": [
    "!pip install nbconvert\n",
    "from google.colab import files\n",
    "!jupyter nbconvert --to html \"/content/YourNotebookName.ipynb\"\n",
    "files.download(\"/content/YourNotebookName.html\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1NWibR39ET4fRuz-YAGVJwhp1X3H4Pmrg",
     "timestamp": 1731517475781
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
